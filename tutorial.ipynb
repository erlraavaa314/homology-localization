{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the homology-localization package\n",
    "This is a simple tutorial showing you how to use the homology-localization package to localize a homology class.\n",
    "## Content\n",
    "This tutorial shows you the three steps required to localize a homology class using our package\n",
    "\n",
    "1) Import the function \"localize\"\n",
    "\n",
    "2) Make sure \"localize\" is given correct input\n",
    "\n",
    "3) Interpreting the output of \"localize\"\n",
    "\n",
    "A description of the algorithms that are implemented in this package is presented in the paper (Refer to paper later) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Importing the Interface\n",
    "We will operate the package via the function called \"localize\" in the file \"interface.py\". This is just a wrapper function that makes it easier to make use of the package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homology_localization.interface import localize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Encoding an Input Instance\n",
    "The function \"localize\" needs 3 arguements, the first three of which are used to specify a problem instance. This means providing the $d+1$-simplicies of the complex, a $d$-cycle and a weight function for each $d$-simplex. Let us look at the following simple and concrete example for $d = 1$: \n",
    "\n",
    "![title](img/tutorial_example-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First: Encoding the $d+1$-simplices\n",
    "The $2$-simplices of this simplicial complex are\n",
    "- $x = \\{2,3,4\\}$ (blue)\n",
    "- $y = \\{3,4,5\\}$ (yellow)\n",
    "- $z = \\{2,4,5\\}$ (red).\n",
    "\n",
    "Each $(d+1)$ should be coded as a frozenset, which are then placed in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = frozenset([2,3,4])\n",
    "y = frozenset([3,4,5])\n",
    "z = frozenset([2,4,5])\n",
    "simplices = [x,y,z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second: Encoding the $d$-simplices and their weights:\n",
    "\n",
    "Next we need to assign weights to all the $1$-simplices in the simplicial complex. This is coded using a dictionary where the keys are $1$-simplices (coded as frozenset) and the value of each key is its weight. First, let us set all the weights to be one. The $1$-simplices of the simplicial complex are:\n",
    "- $a = \\{1,2\\}$\n",
    "- $b = \\{1,3\\}$\n",
    "- $c = \\{2,3\\}$\n",
    "- $d = \\{2,4\\}$\n",
    "- $e = \\{2,5\\}$\n",
    "- $f = \\{3,4\\}$ \n",
    "- $g = \\{3,5\\}$ \n",
    "- $h = \\{4,5\\}$ \n",
    "So we can code the weights as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = frozenset([1,2])\n",
    "b = frozenset([1,3])\n",
    "c = frozenset([2,3])\n",
    "d = frozenset([2,4])\n",
    "e = frozenset([2,5])\n",
    "f = frozenset([3,4])\n",
    "g = frozenset([3,5])\n",
    "h = frozenset([4,5])\n",
    "one_simplices = [a,b,c,d,e,f,g,h]\n",
    "weights = {simplex : 1 for simplex in one_simplices}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third: Encoding the input cycle\n",
    "Say that we want to localize the $1$-cycle containing the simplicies $a = \\{1,2\\}, e= \\{2,5\\}, g = \\{3,5\\}, b= \\{1,3\\}$, then we encode this as the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = [a,e,g,b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Interpreting the output\n",
    "Before we can interpret the output we need to call the function. This is simple, just write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_size, solution, memory = localize(simplices, weights, cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "The name of the return variables should give some indication of what they contain, but we add the following to be precise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the localized cycle is: 3.0\n",
      "The localized cycle contains the following 1-simplices: [frozenset({1, 2}), frozenset({1, 3}), frozenset({2, 3})]\n",
      "The algorithm used this much ''memory'': 10\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the localized cycle is: \" + str(solution_size))\n",
    "print(\"The localized cycle contains the following 1-simplices: \" + str(solution))\n",
    "print(\"The algorithm used this much ''memory'': \" + str(memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notion of ''memory'' is perhaps still a bit unclear. It refers to the number of entries the algorithm needs to store in its dictionary when solving the problem. See our paper for details on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some other weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([frozenset({1, 2}), frozenset({1, 3}), frozenset({2, 4}), frozenset({3, 4})], 6.0, 10)\n",
      "([frozenset({1, 2}), frozenset({1, 3}), frozenset({3, 5}), frozenset({2, 4}), frozenset({4, 5})], 3.0, 10)\n"
     ]
    }
   ],
   "source": [
    "weights = {a:0, b:0, c:10, d:2, e:3, f:4, g:5, h:6}\n",
    "solution_size, solution, memory = localize(simplices, weights, cycle)\n",
    "out = (solution, solution_size, memory)\n",
    "print(out)\n",
    "weights = {a:0, b:0, c:100, d:1, e:100, f:100, g:1, h:1}\n",
    "solution_size, solution, memory = localize(simplices, weights, cycle)\n",
    "out = (solution, solution_size, memory)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further input arguements:\n",
    "The function \"localize\" takes two more arguements as inputs:\n",
    "- A boolean value telling which of the two algorithms should be used\n",
    "- An integer arguement allowing the user to set a custom upper limit on memory use.\n",
    "\n",
    "Running \"localize(simplices, weights, cycle)\" is the same as calling localize(simplices, weights, cycle, True, 2** 20). I.e. we run the algorithm based on the Hasse diagram of the simplicial complex and that the program crashes once the algorithm has tried to store $2^{20}$ entries. \n",
    "\n",
    "If we change call \"localize(simplices, weights, cycle, False)\" instead we, use the algorithm based on the Connectivity graph of the simplicial complex. We will typically see that the amount of ''memory'' used changes while the rest of the output remains the same. Let us run the code using the same set of weights as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([frozenset({3, 4}), frozenset({2, 4}), frozenset({1, 2}), frozenset({1, 3})], 6.0, 16)\n",
      "([frozenset({3, 5}), frozenset({2, 4}), frozenset({4, 5}), frozenset({1, 2}), frozenset({1, 3})], 3.0, 16)\n"
     ]
    }
   ],
   "source": [
    "weights = {a:0, b:0, c:10, d:2, e:3, f:4, g:5, h:6}\n",
    "solution_size, solution, memory = localize(simplices, weights, cycle, False)\n",
    "out = (solution, solution_size, memory)\n",
    "print(out)\n",
    "weights = {a:0, b:0, c:100, d:1, e:100, f:100, g:1, h:1}\n",
    "solution_size, solution, memory = localize(simplices, weights, cycle, False)\n",
    "out = (solution, solution_size, memory)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the MemoryLimitViolation error\n",
    "\n",
    "If we set the memory limit to 13 (above 10, below 16) we see that everything is fine during the first call, using the algorithm based on the Hasse diagram (which needs only store 10 entries) while the second call crashes as the algorithm based on the Connectivity graph needs to store 16 entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0, [frozenset({1, 2}), frozenset({1, 3}), frozenset({3, 5}), frozenset({2, 4}), frozenset({4, 5})], 10)\n"
     ]
    },
    {
     "ename": "MemoryLimitViolation",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryLimitViolation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0cb7cd0f628d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimplices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimplices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\PycharmProjects\\homology-localization\\homology_localization\\interface.py\u001b[0m in \u001b[0;36mlocalize\u001b[1;34m(simplices, weights, cycle, hasse_diagram, memory_limit)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlocalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimplices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasse_diagram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mhomloc_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHomLoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimplices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhomloc_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhomology_localization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasse_diagram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\homology-localization\\homology_localization\\algorithms\\hom_loc.py\u001b[0m in \u001b[0;36mhomology_localization\u001b[1;34m(self, spine_graph, print_status, output_homologous_cycle)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moutput_homologous_cycle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mhom_loc_cg_rep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain_complex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mhom_loc_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain_complex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\homology-localization\\homology_localization\\algorithms\\hom_loc_cg_rep.py\u001b[0m in \u001b[0;36mhom_loc_cg_rep\u001b[1;34m(cc, v_set, give_status, memory_limit)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mmemory_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mchild_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchildren_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbag_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforget_rep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbag_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchildren_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\homology-localization\\homology_localization\\algorithms\\hom_loc_cg_rep.py\u001b[0m in \u001b[0;36mforget_rep\u001b[1;34m(child_table, bag_id, child_id, cc, v, u, memory, memory_limit)\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmemory\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmemory_limit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mMemoryLimitViolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[0mu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbag_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryLimitViolation\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(localize(simplices, weights, cycle, True, 13))\n",
    "print(localize(simplices, weights, cycle, False, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two more functions:\n",
    "\n",
    "The interface file has two more usefull functions: \"treewidth\" and \"number_of_bags_in_treedecomposition\". Given a simplicial complex these function compute the width of and number of bags in the treedecomposition that will be used by the algorithm to compute a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The width of the decomposition of the Hasse diagram is: 2\n",
      "The width of the decomposition of the Connectivity graph is : 2\n",
      "The number of bags in the tree decomposition of the Hasse diagram is: 43\n",
      "The number of bags in the tree decomposition of the Connectivity graph is: 7\n"
     ]
    }
   ],
   "source": [
    "from homology_localization.interface import treewidth, number_of_bags_in_treedecomposition\n",
    "\n",
    "print(\"The width of the decomposition of the Hasse diagram is: \" + str(treewidth(simplices, weights, True)))\n",
    "print(\"The width of the decomposition of the Connectivity graph is : \" + str(treewidth(simplices, weights, False)))\n",
    "print(\"The number of bags in the tree decomposition of the Hasse diagram is: \" + str(number_of_bags_in_treedecomposition(simplices, weights, True)))\n",
    "print(\"The number of bags in the tree decomposition of the Connectivity graph is: \" + str(number_of_bags_in_treedecomposition(simplices, weights, False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems with low treewidth tends to be conciderably easier to solve than those with large treewidth. Computing the treewidth in advance gets us a very good estimate on how long the algorithm will need in order to terminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding Remarks\n",
    "This was a short tutorial on how you can use the package homology-localization through the interface function \"localize\". If you have questions about our code please do not hesitate to contact us. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
